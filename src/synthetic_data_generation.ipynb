{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation (SDG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa41003547324b508bdec1ae7998cb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/72742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.schema import Document\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"motionlabs/fineweb-ultra-mini\",\n",
    "    cache_dir=\"/mnt/d/datasets/fineweb-ultra-mini\"\n",
    ")\n",
    "\n",
    "selected_data = dataset['train'].select(range(3))\n",
    "texts = [item['text'] for item in selected_data]\n",
    "\n",
    "# Convert texts to LangChain Document objects\n",
    "docs = [Document(page_content=text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_headlines(text):\n",
    "    # This regex matches lines that start with a number followed by a period or parenthesis\n",
    "    return re.findall(r'^\\d+\\.*\\s*(.*)', text, re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    headlines = extract_headlines(doc.page_content)\n",
    "    if not headlines:\n",
    "        headlines = ['No headlines found']\n",
    "    doc.metadata['headlines'] = headlines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mounty-ed/stuff/RAG_research/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, the user said \"hi\". I need to respond appropriately. Since it\\'s a simple greeting, I should acknowledge their greeting and offer assistance. Maybe start with a friendly \"Hello!\" and ask how I can help. Keep it open-ended so they feel comfortable to ask anything. Make sure the tone is positive and welcoming. Let me check if there\\'s anything else needed. No, that should cover it. Alright, time to put it all together.\\n</think>\\n\\nHello! ðŸ˜Š How can I assist you today? I\\'m here to help with any questions or tasks you might have!' additional_kwargs={} response_metadata={'model': 'qwen3:8b', 'created_at': '2025-08-13T02:48:35.91344224Z', 'done': True, 'done_reason': 'stop', 'total_duration': 24028804272, 'load_duration': 19189712961, 'prompt_eval_count': 9, 'prompt_eval_duration': 482973816, 'eval_count': 122, 'eval_duration': 4353258620, 'model_name': 'qwen3:8b'} id='run--fcaeb002-6783-430c-a700-180d63ba9617-0' usage_metadata={'input_tokens': 9, 'output_tokens': 122, 'total_tokens': 131}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mounty-ed/stuff/RAG_research/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1070 Ti which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/home/mounty-ed/stuff/RAG_research/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/home/mounty-ed/stuff/RAG_research/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1070 Ti with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_llm = ChatOllama(\n",
    "    model=\"qwen3:8b\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "print(generator_llm.invoke(\"hi\"))\n",
    "\n",
    "generator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "wrapped_llm = LangchainLLMWrapper(generator_llm)\n",
    "wrapped_embeddings = LangchainEmbeddingsWrapper(generator_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs, testset_size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What contributions has Han Zhou made to the fi...</td>\n",
       "      <td>[5 2 0 2 b e F 4 ] G L . s c [ 1 v 3 3 5 2 0 ....</td>\n",
       "      <td>Han Zhou is one of the authors of a study that...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do Kojima et al. contribute to the underst...</td>\n",
       "      <td>[1. Introduction Exemplar Topology Optimizer d...</td>\n",
       "      <td>Kojima et al. (2022) contribute to the underst...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of prompt design in m...</td>\n",
       "      <td>[2.1. Block-level: Prompt Design for Agents At...</td>\n",
       "      <td>The significance of prompt design in multi-age...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What were the key factors contributing to Meta...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion In summary, 2024 was a ...</td>\n",
       "      <td>Meta's stock gain of 72% in 2024 was driven by...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do the findings of Madaan et al. regarding...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2.2. Workflow-level Search Space D...</td>\n",
       "      <td>Madaan et al. emphasize the significance of se...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was Amazon's stock performance in 2024 an...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nStock Market Performance in 2024 U...</td>\n",
       "      <td>Amazon's stock staged an impressive rebound in...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What contributions has Han Zhou made to the fi...   \n",
       "1  How do Kojima et al. contribute to the underst...   \n",
       "2  What is the significance of prompt design in m...   \n",
       "3  What were the key factors contributing to Meta...   \n",
       "4  How do the findings of Madaan et al. regarding...   \n",
       "5  What was Amazon's stock performance in 2024 an...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [5 2 0 2 b e F 4 ] G L . s c [ 1 v 3 3 5 2 0 ....   \n",
       "1  [1. Introduction Exemplar Topology Optimizer d...   \n",
       "2  [2.1. Block-level: Prompt Design for Agents At...   \n",
       "3  [<1-hop>\\n\\nConclusion In summary, 2024 was a ...   \n",
       "4  [<1-hop>\\n\\n2.2. Workflow-level Search Space D...   \n",
       "5  [<1-hop>\\n\\nStock Market Performance in 2024 U...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Han Zhou is one of the authors of a study that...   \n",
       "1  Kojima et al. (2022) contribute to the underst...   \n",
       "2  The significance of prompt design in multi-age...   \n",
       "3  Meta's stock gain of 72% in 2024 was driven by...   \n",
       "4  Madaan et al. emphasize the significance of se...   \n",
       "5  Amazon's stock staged an impressive rebound in...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  multi_hop_specific_query_synthesizer  \n",
       "4  multi_hop_specific_query_synthesizer  \n",
       "5  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame as CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 4), (6, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.to_csv(\"./data/eval_dataframe.csv\", index=False)\n",
    "\n",
    "loaded_df = pd.read_csv(\"./data/eval_dataframe.csv\")\n",
    "\n",
    "df.shape, loaded_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame as Parquet\n",
    "\n",
    "This format is for larger datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 4), (12, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.to_parquet(\"../data/eval_dataframe.parquet\")\n",
    "\n",
    "# loaded_df = pd.read_parquet(\"../data/eval_dataframe.parquet\")\n",
    "\n",
    "# df.shape, loaded_df.shape\n",
    "# ## Saving DataFrame as Feather\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
