{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation (SDG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mounty-ed/stuff/agentic_stuff/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"./data/samples/\"\n",
    "loader = DirectoryLoader(path)\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/36 [00:00<?, ?it/s]/home/mounty-ed/stuff/agentic_stuff/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Generating personas: 100%|██████████| 2/2 [00:01<00:00,  1.90it/s]                                           \n",
      "Generating Scenarios: 100%|██████████| 2/2 [00:05<00:00,  2.73s/it]\n",
      "Generating Samples: 100%|██████████| 6/6 [00:04<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from ragas.testset import TestsetGenerator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "generator_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "generator_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "wrapped_llm = LangchainLLMWrapper(generator_llm)\n",
    "wrapped_embeddings = LangchainEmbeddingsWrapper(generator_embeddings)\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs, testset_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What contributions has Han Zhou made to the fi...</td>\n",
       "      <td>[5 2 0 2 b e F 4 ] G L . s c [ 1 v 3 3 5 2 0 ....</td>\n",
       "      <td>Han Zhou is one of the authors of a study that...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do Kojima et al. contribute to the underst...</td>\n",
       "      <td>[1. Introduction Exemplar Topology Optimizer d...</td>\n",
       "      <td>Kojima et al. (2022) contribute to the underst...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of prompt design in m...</td>\n",
       "      <td>[2.1. Block-level: Prompt Design for Agents At...</td>\n",
       "      <td>The significance of prompt design in multi-age...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What were the key factors contributing to Meta...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nConclusion In summary, 2024 was a ...</td>\n",
       "      <td>Meta's stock gain of 72% in 2024 was driven by...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do the findings of Madaan et al. regarding...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2.2. Workflow-level Search Space D...</td>\n",
       "      <td>Madaan et al. emphasize the significance of se...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was Amazon's stock performance in 2024 an...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nStock Market Performance in 2024 U...</td>\n",
       "      <td>Amazon's stock staged an impressive rebound in...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What contributions has Han Zhou made to the fi...   \n",
       "1  How do Kojima et al. contribute to the underst...   \n",
       "2  What is the significance of prompt design in m...   \n",
       "3  What were the key factors contributing to Meta...   \n",
       "4  How do the findings of Madaan et al. regarding...   \n",
       "5  What was Amazon's stock performance in 2024 an...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [5 2 0 2 b e F 4 ] G L . s c [ 1 v 3 3 5 2 0 ....   \n",
       "1  [1. Introduction Exemplar Topology Optimizer d...   \n",
       "2  [2.1. Block-level: Prompt Design for Agents At...   \n",
       "3  [<1-hop>\\n\\nConclusion In summary, 2024 was a ...   \n",
       "4  [<1-hop>\\n\\n2.2. Workflow-level Search Space D...   \n",
       "5  [<1-hop>\\n\\nStock Market Performance in 2024 U...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Han Zhou is one of the authors of a study that...   \n",
       "1  Kojima et al. (2022) contribute to the underst...   \n",
       "2  The significance of prompt design in multi-age...   \n",
       "3  Meta's stock gain of 72% in 2024 was driven by...   \n",
       "4  Madaan et al. emphasize the significance of se...   \n",
       "5  Amazon's stock staged an impressive rebound in...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  multi_hop_specific_query_synthesizer  \n",
       "4  multi_hop_specific_query_synthesizer  \n",
       "5  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame as CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 4), (6, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.to_csv(\"./data/eval_dataframe.csv\", index=False)\n",
    "\n",
    "loaded_df = pd.read_csv(\"./data/eval_dataframe.csv\")\n",
    "\n",
    "df.shape, loaded_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame as Parquet\n",
    "\n",
    "This format is for larger datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 4), (12, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.to_parquet(\"../data/eval_dataframe.parquet\")\n",
    "\n",
    "# loaded_df = pd.read_parquet(\"../data/eval_dataframe.parquet\")\n",
    "\n",
    "# df.shape, loaded_df.shape\n",
    "# ## Saving DataFrame as Feather\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
